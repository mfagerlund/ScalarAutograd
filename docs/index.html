<!DOCTYPE html><html class="default" lang="en" data-base="./"><head><meta charset="utf-8"/><meta http-equiv="x-ua-compatible" content="IE=edge"/><title>scalar-autograd</title><meta name="description" content="Documentation for scalar-autograd"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="stylesheet" href="assets/style.css"/><link rel="stylesheet" href="assets/highlight.css"/><script defer src="assets/main.js"></script><script async src="assets/icons.js" id="tsd-icons-script"></script><script async src="assets/search.js" id="tsd-search-script"></script><script async src="assets/navigation.js" id="tsd-nav-script"></script></head><body><script>document.documentElement.dataset.theme = localStorage.getItem("tsd-theme") || "os";document.body.style.display="none";setTimeout(() => window.app?app.showPage():document.body.style.removeProperty("display"),500)</script><header class="tsd-page-toolbar"><div class="tsd-toolbar-contents container"><a href="index.html" class="title">scalar-autograd</a><div id="tsd-toolbar-links"></div><button id="tsd-search-trigger" class="tsd-widget" aria-label="Search"><svg width="16" height="16" viewBox="0 0 16 16" fill="none" aria-hidden="true"><use href="assets/icons.svg#icon-search"></use></svg></button><dialog id="tsd-search" aria-label="Search"><input role="combobox" id="tsd-search-input" aria-controls="tsd-search-results" aria-autocomplete="list" aria-expanded="true" autocapitalize="off" autocomplete="off" placeholder="Search the docs" maxLength="100"/><ul role="listbox" id="tsd-search-results"></ul><div id="tsd-search-status" aria-live="polite" aria-atomic="true"><div>Preparing search index...</div></div></dialog><a href="#" class="tsd-widget menu" id="tsd-toolbar-menu-trigger" data-toggle="menu" aria-label="Menu"><svg width="16" height="16" viewBox="0 0 16 16" fill="none" aria-hidden="true"><use href="assets/icons.svg#icon-menu"></use></svg></a></div></header><div class="container container-main"><div class="col-content"><div class="tsd-page-title"><h1>scalar-autograd</h1></div><div class="tsd-panel tsd-typography"><h1 id="scalarautograd-for-typescript" class="tsd-anchor-link">ScalarAutograd for TypeScript<a href="#scalarautograd-for-typescript" aria-label="Permalink" class="tsd-anchor-icon"><svg viewBox="0 0 24 24" aria-hidden="true"><use href="assets/icons.svg#icon-anchor"></use></svg></a></h1><p>A tiny scalar autograd engine for TypeScript/JavaScript.</p>
<p>Scautograd enables automatic differentiation for scalar operations, similar to what you'd find in PyTorch's <code>autograd</code>, but designed for TypeScript codebases. This makes it useful for building and training small neural networks, performing optimization, or experimenting with gradient-based techniquesâ€”entirely in the browser or Node.js.</p>
<h2 id="features" class="tsd-anchor-link">Features<a href="#features" aria-label="Permalink" class="tsd-anchor-icon"><svg viewBox="0 0 24 24" aria-hidden="true"><use href="assets/icons.svg#icon-anchor"></use></svg></a></h2><ul>
<li>Scalar <code>Value</code> objects for tracking data, gradients, and computation graph.</li>
<li>Backpropagation via <code>.backward()</code> to compute gradients automatically.</li>
<li>Clean, TypeScript-first API.</li>
<li>Does <em>NOT</em> handle matrices or tensors, just scalars.</li>
</ul>
<h2 id="installation" class="tsd-anchor-link">Installation<a href="#installation" aria-label="Permalink" class="tsd-anchor-icon"><svg viewBox="0 0 24 24" aria-hidden="true"><use href="assets/icons.svg#icon-anchor"></use></svg></a></h2><p>Simply copy the files in this folder into your project, or import as a local module if desired.</p>
<h2 id="basic-usage" class="tsd-anchor-link">Basic Usage<a href="#basic-usage" aria-label="Permalink" class="tsd-anchor-icon"><svg viewBox="0 0 24 24" aria-hidden="true"><use href="assets/icons.svg#icon-anchor"></use></svg></a></h2><pre><code class="typescript"><span class="hl-0">import</span><span class="hl-1"> { </span><span class="hl-2">V</span><span class="hl-1"> } </span><span class="hl-0">from</span><span class="hl-1"> </span><span class="hl-3">&#39;./V&#39;</span><span class="hl-1">;</span><br/><br/><span class="hl-4">// Basic differentiation using static V API</span><br/><span class="hl-5">const</span><span class="hl-1"> </span><span class="hl-6">x</span><span class="hl-1"> = </span><span class="hl-6">V</span><span class="hl-1">.</span><span class="hl-7">W</span><span class="hl-1">(</span><span class="hl-8">2.0</span><span class="hl-1">); </span><span class="hl-4">// differentiable variable</span><br/><span class="hl-5">const</span><span class="hl-1"> </span><span class="hl-6">y</span><span class="hl-1"> = </span><span class="hl-6">V</span><span class="hl-1">.</span><span class="hl-7">W</span><span class="hl-1">(</span><span class="hl-8">3.0</span><span class="hl-1">);</span><br/><span class="hl-5">const</span><span class="hl-1"> </span><span class="hl-6">z</span><span class="hl-1"> = </span><span class="hl-6">V</span><span class="hl-1">.</span><span class="hl-7">add</span><span class="hl-1">(</span><span class="hl-6">V</span><span class="hl-1">.</span><span class="hl-7">mul</span><span class="hl-1">(</span><span class="hl-2">x</span><span class="hl-1">, </span><span class="hl-2">y</span><span class="hl-1">), </span><span class="hl-6">V</span><span class="hl-1">.</span><span class="hl-7">pow</span><span class="hl-1">(</span><span class="hl-2">x</span><span class="hl-1">, </span><span class="hl-8">2</span><span class="hl-1">)); </span><span class="hl-4">// z = x*y + x^2</span><br/><span class="hl-2">z</span><span class="hl-1">.</span><span class="hl-7">backward</span><span class="hl-1">();</span><br/><span class="hl-2">console</span><span class="hl-1">.</span><span class="hl-7">log</span><span class="hl-1">(</span><span class="hl-3">&#39;dz/dx:&#39;</span><span class="hl-1">, </span><span class="hl-2">x</span><span class="hl-1">.</span><span class="hl-2">grad</span><span class="hl-1">); </span><span class="hl-4">// Output: dz/dx = y + 2*x = 3 + 2*2 = 7</span><br/><span class="hl-2">console</span><span class="hl-1">.</span><span class="hl-7">log</span><span class="hl-1">(</span><span class="hl-3">&#39;dz/dy:&#39;</span><span class="hl-1">, </span><span class="hl-2">y</span><span class="hl-1">.</span><span class="hl-2">grad</span><span class="hl-1">); </span><span class="hl-4">// Output: dz/dy = x = 2</span>
</code><button type="button">Copy</button></pre>

<h2 id="example-tiny-gradient-descent" class="tsd-anchor-link">Example: Tiny Gradient Descent<a href="#example-tiny-gradient-descent" aria-label="Permalink" class="tsd-anchor-icon"><svg viewBox="0 0 24 24" aria-hidden="true"><use href="assets/icons.svg#icon-anchor"></use></svg></a></h2><pre><code class="typescript"><span class="hl-5">const</span><span class="hl-1"> </span><span class="hl-6">a</span><span class="hl-1"> = </span><span class="hl-6">V</span><span class="hl-1">.</span><span class="hl-7">W</span><span class="hl-1">(</span><span class="hl-8">5</span><span class="hl-1">);</span><br/><span class="hl-5">const</span><span class="hl-1"> </span><span class="hl-6">b</span><span class="hl-1"> = </span><span class="hl-6">V</span><span class="hl-1">.</span><span class="hl-7">W</span><span class="hl-1">(-</span><span class="hl-8">3</span><span class="hl-1">);</span><br/><span class="hl-5">const</span><span class="hl-1"> </span><span class="hl-6">c</span><span class="hl-1"> = </span><span class="hl-6">V</span><span class="hl-1">.</span><span class="hl-7">sin</span><span class="hl-1">(</span><span class="hl-6">V</span><span class="hl-1">.</span><span class="hl-7">mul</span><span class="hl-1">(</span><span class="hl-2">a</span><span class="hl-1">, </span><span class="hl-2">b</span><span class="hl-1">)); </span><span class="hl-4">// f = sin(a * b)</span><br/><span class="hl-2">c</span><span class="hl-1">.</span><span class="hl-7">backward</span><span class="hl-1">();</span><br/><span class="hl-2">console</span><span class="hl-1">.</span><span class="hl-7">log</span><span class="hl-1">(</span><span class="hl-2">a</span><span class="hl-1">.</span><span class="hl-2">grad</span><span class="hl-1">, </span><span class="hl-2">b</span><span class="hl-1">.</span><span class="hl-2">grad</span><span class="hl-1">); </span><span class="hl-4">// Gradients w.r.t. a and b</span>
</code><button type="button">Copy</button></pre>

<h2 id="example-solving-for-parameters-via-backpropagation" class="tsd-anchor-link">Example: Solving for Parameters via Backpropagation<a href="#example-solving-for-parameters-via-backpropagation" aria-label="Permalink" class="tsd-anchor-icon"><svg viewBox="0 0 24 24" aria-hidden="true"><use href="assets/icons.svg#icon-anchor"></use></svg></a></h2><p>Here's how you can use Scautograd's backpropagation and a simple optimizer to fit a linear regression model (y = 2x + 3):</p>
<pre><code class="typescript"><span class="hl-0">import</span><span class="hl-1"> { </span><span class="hl-2">V</span><span class="hl-1"> } </span><span class="hl-0">from</span><span class="hl-1"> </span><span class="hl-3">&#39;./V&#39;</span><span class="hl-1">;</span><br/><span class="hl-0">import</span><span class="hl-1"> { </span><span class="hl-2">SGD</span><span class="hl-1"> } </span><span class="hl-0">from</span><span class="hl-1"> </span><span class="hl-3">&#39;./Optimizers&#39;</span><span class="hl-1">;</span><br/><br/><span class="hl-4">// Initialize parameters</span><br/><span class="hl-5">let</span><span class="hl-1"> </span><span class="hl-2">w</span><span class="hl-1"> = </span><span class="hl-6">V</span><span class="hl-1">.</span><span class="hl-7">W</span><span class="hl-1">(</span><span class="hl-2">Math</span><span class="hl-1">.</span><span class="hl-7">random</span><span class="hl-1">(), </span><span class="hl-3">&quot;w&quot;</span><span class="hl-1">);</span><br/><span class="hl-5">let</span><span class="hl-1"> </span><span class="hl-2">b</span><span class="hl-1"> = </span><span class="hl-6">V</span><span class="hl-1">.</span><span class="hl-7">W</span><span class="hl-1">(</span><span class="hl-2">Math</span><span class="hl-1">.</span><span class="hl-7">random</span><span class="hl-1">(), </span><span class="hl-3">&quot;b&quot;</span><span class="hl-1">);</span><br/><br/><span class="hl-4">// Example data: y = 2x + 3</span><br/><span class="hl-5">const</span><span class="hl-1"> </span><span class="hl-6">samples</span><span class="hl-1"> = [</span><br/><span class="hl-1">  { </span><span class="hl-2">x:</span><span class="hl-1"> </span><span class="hl-8">1</span><span class="hl-1">, </span><span class="hl-2">y:</span><span class="hl-1"> </span><span class="hl-8">5</span><span class="hl-1"> },</span><br/><span class="hl-1">  { </span><span class="hl-2">x:</span><span class="hl-1"> </span><span class="hl-8">2</span><span class="hl-1">, </span><span class="hl-2">y:</span><span class="hl-1"> </span><span class="hl-8">7</span><span class="hl-1"> },</span><br/><span class="hl-1">  { </span><span class="hl-2">x:</span><span class="hl-1"> </span><span class="hl-8">3</span><span class="hl-1">, </span><span class="hl-2">y:</span><span class="hl-1"> </span><span class="hl-8">9</span><span class="hl-1"> },</span><br/><span class="hl-1">];</span><br/><br/><span class="hl-5">const</span><span class="hl-1"> </span><span class="hl-6">opt</span><span class="hl-1"> = </span><span class="hl-5">new</span><span class="hl-1"> </span><span class="hl-7">SGD</span><span class="hl-1">([</span><span class="hl-2">w</span><span class="hl-1">, </span><span class="hl-2">b</span><span class="hl-1">], { </span><span class="hl-2">learningRate:</span><span class="hl-1"> </span><span class="hl-8">0.1</span><span class="hl-1"> });</span><br/><br/><span class="hl-0">for</span><span class="hl-1"> (</span><span class="hl-5">let</span><span class="hl-1"> </span><span class="hl-2">epoch</span><span class="hl-1"> = </span><span class="hl-8">0</span><span class="hl-1">; </span><span class="hl-2">epoch</span><span class="hl-1"> &lt; </span><span class="hl-8">300</span><span class="hl-1">; ++</span><span class="hl-2">epoch</span><span class="hl-1">) {</span><br/><span class="hl-1">  </span><span class="hl-5">let</span><span class="hl-1"> </span><span class="hl-2">losses</span><span class="hl-1"> = [];</span><br/><span class="hl-1">  </span><span class="hl-0">for</span><span class="hl-1"> (</span><span class="hl-5">const</span><span class="hl-1"> </span><span class="hl-6">sample</span><span class="hl-1"> </span><span class="hl-5">of</span><span class="hl-1"> </span><span class="hl-2">samples</span><span class="hl-1">) {</span><br/><span class="hl-1">    </span><span class="hl-5">const</span><span class="hl-1"> </span><span class="hl-6">x</span><span class="hl-1"> = </span><span class="hl-6">V</span><span class="hl-1">.</span><span class="hl-7">C</span><span class="hl-1">(</span><span class="hl-2">sample</span><span class="hl-1">.</span><span class="hl-2">x</span><span class="hl-1">, </span><span class="hl-3">&quot;x&quot;</span><span class="hl-1">);</span><br/><span class="hl-1">    </span><span class="hl-5">const</span><span class="hl-1"> </span><span class="hl-6">pred</span><span class="hl-1"> = </span><span class="hl-6">V</span><span class="hl-1">.</span><span class="hl-7">add</span><span class="hl-1">(</span><span class="hl-6">V</span><span class="hl-1">.</span><span class="hl-7">mul</span><span class="hl-1">(</span><span class="hl-2">w</span><span class="hl-1">, </span><span class="hl-2">x</span><span class="hl-1">), </span><span class="hl-2">b</span><span class="hl-1">);</span><br/><span class="hl-1">    </span><span class="hl-5">const</span><span class="hl-1"> </span><span class="hl-6">target</span><span class="hl-1"> = </span><span class="hl-6">V</span><span class="hl-1">.</span><span class="hl-7">C</span><span class="hl-1">(</span><span class="hl-2">sample</span><span class="hl-1">.</span><span class="hl-2">y</span><span class="hl-1">, </span><span class="hl-3">&quot;target&quot;</span><span class="hl-1">);</span><br/><span class="hl-1">    </span><span class="hl-5">const</span><span class="hl-1"> </span><span class="hl-6">loss</span><span class="hl-1"> = </span><span class="hl-6">V</span><span class="hl-1">.</span><span class="hl-7">pow</span><span class="hl-1">(</span><span class="hl-6">V</span><span class="hl-1">.</span><span class="hl-7">sub</span><span class="hl-1">(</span><span class="hl-2">pred</span><span class="hl-1">, </span><span class="hl-2">target</span><span class="hl-1">), </span><span class="hl-8">2</span><span class="hl-1">);</span><br/><span class="hl-1">    </span><span class="hl-2">losses</span><span class="hl-1">.</span><span class="hl-7">push</span><span class="hl-1">(</span><span class="hl-2">loss</span><span class="hl-1">);</span><br/><span class="hl-1">  }</span><br/><span class="hl-1">  </span><span class="hl-5">const</span><span class="hl-1"> </span><span class="hl-6">totalLoss</span><span class="hl-1"> = </span><span class="hl-6">V</span><span class="hl-1">.</span><span class="hl-7">mean</span><span class="hl-1">(</span><span class="hl-2">losses</span><span class="hl-1">);</span><br/><span class="hl-1">  </span><span class="hl-2">opt</span><span class="hl-1">.</span><span class="hl-7">zeroGrad</span><span class="hl-1">();</span><br/><span class="hl-1">  </span><span class="hl-2">totalLoss</span><span class="hl-1">.</span><span class="hl-7">backward</span><span class="hl-1">();</span><br/><span class="hl-1">  </span><span class="hl-2">opt</span><span class="hl-1">.</span><span class="hl-7">step</span><span class="hl-1">();</span><br/><span class="hl-1">  </span><span class="hl-0">if</span><span class="hl-1"> (</span><span class="hl-2">totalLoss</span><span class="hl-1">.</span><span class="hl-2">data</span><span class="hl-1"> &lt; </span><span class="hl-8">1e-4</span><span class="hl-1">) </span><span class="hl-0">break</span><span class="hl-1">;</span><br/><span class="hl-1">}</span><br/><br/><span class="hl-2">console</span><span class="hl-1">.</span><span class="hl-7">log</span><span class="hl-1">(</span><span class="hl-3">&#39;Fitted w:&#39;</span><span class="hl-1">, </span><span class="hl-2">w</span><span class="hl-1">.</span><span class="hl-2">data</span><span class="hl-1">); </span><span class="hl-4">// ~2</span><br/><span class="hl-2">console</span><span class="hl-1">.</span><span class="hl-7">log</span><span class="hl-1">(</span><span class="hl-3">&#39;Fitted b:&#39;</span><span class="hl-1">, </span><span class="hl-2">b</span><span class="hl-1">.</span><span class="hl-2">data</span><span class="hl-1">); </span><span class="hl-4">// ~3</span>
</code><button type="button">Copy</button></pre>

<p>This patternâ€”forward pass, backward for gradients, and calling <code>optimizer.step()</code>â€”applies to more complex optimization tasks and neural networks as well!</p>
<h2 id="api-overview" class="tsd-anchor-link">API Overview<a href="#api-overview" aria-label="Permalink" class="tsd-anchor-icon"><svg viewBox="0 0 24 24" aria-hidden="true"><use href="assets/icons.svg#icon-anchor"></use></svg></a></h2><ul>
<li><strong>Core Value construction:</strong>
<ul>
<li><code>V.C(data, label?)</code> â€” constant (non-differentiable), e.g. for data/inputs.</li>
<li><code>V.W(data, label?)</code> â€” weight/parameter (differentiable).</li>
</ul>
</li>
<li><strong>Operators:</strong>
<ul>
<li>Basic: <code>V.add(a, b)</code>, <code>V.sub(a, b)</code>, <code>V.mul(a, b)</code>, <code>V.div(a, b)</code>, <code>V.pow(a, n)</code>, <code>V.powValue(a, b)</code>.</li>
<li>Reductions: <code>V.sum(array)</code>, <code>V.mean(array)</code></li>
<li>Trig: <code>V.sin(x)</code>, <code>V.cos(x)</code>, <code>V.tan(x)</code>, ...</li>
<li>Activations: <code>V.relu(x)</code>, <code>V.tanh(x)</code>, <code>V.sigmoid(x)</code>, etc.</li>
<li>Comparison: <code>V.eq(a, b)</code>, <code>V.gt(a, b)</code>, ... (outputs constant Values; never has grad)</li>
</ul>
</li>
<li><strong>Backward:</strong>
<ul>
<li><code>.backward()</code> â€” trigger automatic differentiation from this node.</li>
<li><code>.grad</code> â€” access the computed gradient after backward pass.</li>
</ul>
</li>
<li><strong>Optimizers:</strong>
<ul>
<li>E.g. <code>const opt = new SGD([w, b], {learningRate: 0.01})</code></li>
</ul>
</li>
<li><strong>Losses:</strong>
<ul>
<li>Import from <code>Losses.ts</code> (e.g. <code>import { mse } from './Losses'</code>)</li>
</ul>
</li>
</ul>
<p>All API operations work with both <code>Value</code> and raw number inputs (numbers are automatically wrapped as non-grad constants).</p>
<h2 id="testing" class="tsd-anchor-link">Testing<a href="#testing" aria-label="Permalink" class="tsd-anchor-icon"><svg viewBox="0 0 24 24" aria-hidden="true"><use href="assets/icons.svg#icon-anchor"></use></svg></a></h2><p>See the included <code>.spec.ts</code> files for thorough usage and tests.</p>
<h2 id="license" class="tsd-anchor-link">License<a href="#license" aria-label="Permalink" class="tsd-anchor-icon"><svg viewBox="0 0 24 24" aria-hidden="true"><use href="assets/icons.svg#icon-anchor"></use></svg></a></h2><p>MIT</p>
</div></div><div class="col-sidebar"><div class="page-menu"><div class="tsd-navigation settings"><details class="tsd-accordion"><summary class="tsd-accordion-summary"><svg width="20" height="20" viewBox="0 0 24 24" fill="none" aria-hidden="true"><use href="assets/icons.svg#icon-chevronDown"></use></svg><h3>Settings</h3></summary><div class="tsd-accordion-details"><div class="tsd-filter-visibility"><span class="settings-label">Member Visibility</span><ul id="tsd-filter-options"><li class="tsd-filter-item"><label class="tsd-filter-input"><input type="checkbox" id="tsd-filter-protected" name="protected"/><svg width="32" height="32" viewBox="0 0 32 32" aria-hidden="true"><rect class="tsd-checkbox-background" width="30" height="30" x="1" y="1" rx="6" fill="none"></rect><path class="tsd-checkbox-checkmark" d="M8.35422 16.8214L13.2143 21.75L24.6458 10.25" stroke="none" stroke-width="3.5" stroke-linejoin="round" fill="none"></path></svg><span>Protected</span></label></li><li class="tsd-filter-item"><label class="tsd-filter-input"><input type="checkbox" id="tsd-filter-inherited" name="inherited" checked/><svg width="32" height="32" viewBox="0 0 32 32" aria-hidden="true"><rect class="tsd-checkbox-background" width="30" height="30" x="1" y="1" rx="6" fill="none"></rect><path class="tsd-checkbox-checkmark" d="M8.35422 16.8214L13.2143 21.75L24.6458 10.25" stroke="none" stroke-width="3.5" stroke-linejoin="round" fill="none"></path></svg><span>Inherited</span></label></li><li class="tsd-filter-item"><label class="tsd-filter-input"><input type="checkbox" id="tsd-filter-external" name="external"/><svg width="32" height="32" viewBox="0 0 32 32" aria-hidden="true"><rect class="tsd-checkbox-background" width="30" height="30" x="1" y="1" rx="6" fill="none"></rect><path class="tsd-checkbox-checkmark" d="M8.35422 16.8214L13.2143 21.75L24.6458 10.25" stroke="none" stroke-width="3.5" stroke-linejoin="round" fill="none"></path></svg><span>External</span></label></li></ul></div><div class="tsd-theme-toggle"><label class="settings-label" for="tsd-theme">Theme</label><select id="tsd-theme"><option value="os">OS</option><option value="light">Light</option><option value="dark">Dark</option></select></div></div></details></div><details open class="tsd-accordion tsd-page-navigation"><summary class="tsd-accordion-summary"><svg width="20" height="20" viewBox="0 0 24 24" fill="none" aria-hidden="true"><use href="assets/icons.svg#icon-chevronDown"></use></svg><h3>On This Page</h3></summary><div class="tsd-accordion-details"><a href="#scalarautograd-for-typescript"><span>Scalar<wbr/>Autograd for <wbr/>Type<wbr/>Script</span></a><ul><li><a href="#features"><span>Features</span></a></li><li><a href="#installation"><span>Installation</span></a></li><li><a href="#basic-usage"><span>Basic <wbr/>Usage</span></a></li><li><a href="#example-tiny-gradient-descent"><span>Example: <wbr/>Tiny <wbr/>Gradient <wbr/>Descent</span></a></li><li><a href="#example-solving-for-parameters-via-backpropagation"><span>Example: <wbr/>Solving for <wbr/>Parameters via <wbr/>Backpropagation</span></a></li><li><a href="#api-overview"><span>API <wbr/>Overview</span></a></li><li><a href="#testing"><span>Testing</span></a></li><li><a href="#license"><span>License</span></a></li></ul></div></details></div><div class="site-menu"><nav class="tsd-navigation"><a href="modules.html">scalar-autograd</a><ul class="tsd-small-nested-navigation" id="tsd-nav-container"><li>Loading...</li></ul></nav></div></div></div><footer><p class="tsd-generator">Generated using <a href="https://typedoc.org/" target="_blank">TypeDoc</a></p></footer><div class="overlay"></div></body></html>
